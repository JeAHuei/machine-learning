{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the text data\n",
    "\n",
    "* Removal of stop words(such as \"and\",\"the\",\"of\"...)\n",
    "* Lemmatization(such as \"include\",\"includes\" and \"included\" -> \"include\")\n",
    "\n",
    "# Creating word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Dictionary(train_dir):\n",
    "    emails = [os.path.join(train_dir, f) for f in os.listdir(train_dir)]\n",
    "    all_words = []\n",
    "    for mail in emails:\n",
    "        with open(mail)as m:\n",
    "            for i,line in enumerate(m):\n",
    "                if i == 2: # Body of email is only 3rd line of text file\n",
    "                    words = line.split()\n",
    "                    all_words += words\n",
    "    dictionary = Counter(all_words)\n",
    "    # Paste code for non-words removal here(code snippet is given below)\n",
    "    remove_list = dictionary.keys()\n",
    "    list_to_remove = list(remove_list)\n",
    "    for item in list_to_remove:\n",
    "        if item.isalpha() == False:\n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:\n",
    "            del dictionary[item]\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"Machine Learning_Bayes_Lab/ling-spam/train-mails/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = make_Dictionary(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(mail_dir):\n",
    "    files = [os.path.join(mail_dir, fi) for fi in os.listdir(mail_dir)]\n",
    "    features_matrix = np.zeros((len(files),3000))\n",
    "    docID = 0\n",
    "    for fil in files:\n",
    "        with open(fil) as fi:\n",
    "            for i, line in enumerate(fi):\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    for word in words:\n",
    "                        wordID = 0\n",
    "                        for i,d in enumerate(dictionary):\n",
    "                            if d[0] == word:\n",
    "                                wordID = i\n",
    "                                features_matrix[docID, wordID] = words.count(word)\n",
    "            docID = docID + 1\n",
    "    return features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_mail_dir = \"Machine Learning_Bayes_Lab/msg\"\n",
    "spmsg_mail_dir = \"Machine Learning_Bayes_Lab/spmsg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_features_matrix = extract_features(msg_mail_dir)\n",
    "spmsg_features_matrix = extract_features(spmsg_mail_dir)\n",
    "#print(spmsg_features_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionPro(features_matrix):\n",
    "    raws,columns = features_matrix.shape\n",
    "    condPro_list = []\n",
    "    for col in range(columns):\n",
    "        featureVal = 0\n",
    "        for raw in range(raws):\n",
    "            if features_matrix[raw][col] > 0:\n",
    "                featureVal += 1\n",
    "        condPro_list.append(featureVal/raws)\n",
    "    return condPro_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_condPro_list = conditionPro(msg_features_matrix)\n",
    "spmsg_condPro_list = conditionPro(spmsg_features_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"Machine Learning_Bayes_Lab/ling-spam/test-mails/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mails_pro(test_dir):\n",
    "    test_emails = [f for f in os.listdir(test_dir)]\n",
    "    test_emails_sum = len(test_emails)\n",
    "    test_pro_result = [] * 2\n",
    "    test_msg_sum = 0\n",
    "    test_spmsg_sum = 0\n",
    "    for name in test_emails:\n",
    "        names = name.split()\n",
    "        if names[0].isalpha == False:\n",
    "            test_msg_sum += 1\n",
    "        else:\n",
    "            test_spmsg_sum += 1\n",
    "    test_pro_result.append(test_msg_sum/test_emails_sum)\n",
    "    test_pro_result.append(test_spmsg_sum/test_emails_sum)\n",
    "    return test_pro_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_single_mail_features(mail):\n",
    "        single_features_matrix = np.zeros((1,3000))\n",
    "        with open(mail) as ma:\n",
    "            for i, line in enumerate(ma):\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    for word in words:\n",
    "                        wordID = 0\n",
    "                        for i,d in enumerate(dictionary):\n",
    "                            if d[0] == word:\n",
    "                                wordID = i\n",
    "                                single_features_matrix[0, wordID] = words.count(word)\n",
    "        return single_features_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the performance\n",
    "\n",
    "**Naive Bayes** : $$ P(S|W) = \\frac {P(W|S)P(S)}{P(W)}$$ $$ P(S|W_1, W_2,...,W_n) = \\frac {P(W_1, W_2,...,W_n|S)P(S)}{P(W_1, W_2,...,W_n)} \\propto P(W_1, W_2,...,W_n|S)P(S)$$ \n",
    "**When all the features are independent **\n",
    "$$ \\propto P(W_1|S)P(W_2|S)...P(W_n|S)P(S) $$\n",
    "\n",
    "* Compute $P(W_1|S),P(W_2|S),...,P(W_n|S)$ (use `conditionPro`)\n",
    "\n",
    "    * Extract features from spam emails and ham emails, construct $351 * 3000$ features matrix\n",
    "    * For every word in every test email(such as spam) $$ P(W_i|S) = \\frac {the\\ occurence\\ \\#\\ of\\ word\\ in\\ train\\ spam\\ emails}{the\\ \\#\\ of\\ train\\ spam\\ emails} $$\n",
    "    * When $P(W_i|S) = 0$, we use `Laplacian smoothing` $$P(W_i|S) = \\frac {n_1 + 1}{n + N}$$ \n",
    "    \n",
    "    $n_1$ represent the occurence $\\#$ of word(in test emails) in train emails. \n",
    "    \n",
    "    $n$ represent the occurance $\\#$ of all words in train emails\n",
    "    \n",
    "    $N$ represent the $\\#$ of words in train emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9692307692307692 recall 0.9846153846153847 f1 0.9696969696969696\n"
     ]
    }
   ],
   "source": [
    "test_emails = [f for f in os.listdir(test_dir)]\n",
    "prior = test_mails_pro(test_dir)\n",
    "pre_right = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "for mail in test_emails:\n",
    "    msg_likelyhood = 1\n",
    "    spmsg_likelyhood = 1\n",
    "    names = mail.split('.')\n",
    "    if 'spmsgc' in names[0]:\n",
    "        test_result = 1\n",
    "    else:\n",
    "        test_result = 0\n",
    "    mail = os.path.join(test_dir, mail)\n",
    "    mail_features = extract_single_mail_features(mail)\n",
    "    mail_features_index = [i for i in range(3000) if mail_features[0][i]>0]\n",
    "    msg_features_pro = [msg_condPro_list[j] for j in mail_features_index]\n",
    "    spmsg_features_pro = [spmsg_condPro_list[j] for j in mail_features_index]\n",
    "    # Laplacian smoothing\n",
    "    for i in range(len(mail_features_index)):\n",
    "        if msg_features_pro[i] == 0:\n",
    "            words_times = 0\n",
    "            words_all_times = 0\n",
    "            for j in range(351):\n",
    "                words_times += msg_features_matrix[j, mail_features_index[i]]\n",
    "                for k in range(3000):\n",
    "                    words_all_times += msg_features_matrix[j, k]\n",
    "            msg_features_pro[i] = (words_times+1)/(3000 + words_all_times)\n",
    "        msg_likelyhood *= msg_features_pro[i] \n",
    "        if spmsg_features_pro[i] == 0:\n",
    "            words_times = 0\n",
    "            words_all_times = 0\n",
    "            for j in range(351):\n",
    "                words_times += spmsg_features_matrix[j, mail_features_index[i]]\n",
    "                for k in range(3000):\n",
    "                    words_all_times += spmsg_features_matrix[j,k]\n",
    "            spmsg_features_pro[i] = (words_times+1)/(3000 + words_all_times)\n",
    "        spmsg_likelyhood *= spmsg_features_pro[i]\n",
    "    msg_posterior = msg_likelyhood * prior[0]\n",
    "    spmsg_posterior = spmsg_likelyhood * prior[1]\n",
    "    if msg_posterior < spmsg_posterior:\n",
    "        pre_result = 1\n",
    "    else:\n",
    "        pre_result = 0\n",
    "    if pre_result == test_result:\n",
    "        pre_right += 1\n",
    "    if pre_result == 1 and test_result == 0:\n",
    "        fn += 1\n",
    "    if pre_result == 0 and test_result == 0:\n",
    "        tp += 1\n",
    "    if pre_result == 0 and test_result == 1:\n",
    "        fp += 1\n",
    "accuracy = pre_right/len(test_emails)\n",
    "# 召回率：所有正例中正确的概率\n",
    "recall = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print('accuracy',accuracy,'recall',recall,'f1',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|performance|value|\n",
    "|:---------:|:---:|\n",
    "|accurancy|0.9692|\n",
    "|recall|0.9846|\n",
    "|f1|0.9696|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accurancy is about 84.23% when we do not use `Laplacian smoothing`. Obviously, accuracy depends on conditional probability, when the conditional probility is 0, it prones on ham email. \n",
    "\n",
    "Besides, naive bayes as classifier depends on the independence of features. So the results are not ideal and realistic. What's more, there are some issues need to be considered, such as the new words, number of multiples(conditional probability)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
